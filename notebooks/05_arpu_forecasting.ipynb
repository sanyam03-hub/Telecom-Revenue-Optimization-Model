{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddf3ac6",
   "metadata": {},
   "source": [
    "# ARPU Forecasting with Prophet\n",
    "\n",
    "This notebook demonstrates how to use Facebook Prophet for forecasting Average Revenue Per User (ARPU) in a telecom context. We'll build time-series models to predict future revenue and identify trends and seasonal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For Prophet\n",
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# For evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a0b8a",
   "metadata": {},
   "source": [
    "## 1. Generate Time Series Data\n",
    "\n",
    "Since we're working with synthetic data, we'll create a time series dataset that simulates daily ARPU values with trends, seasonality, and noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad7e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arpu_time_series(start_date='2022-01-01', end_date='2024-09-30', base_arpu=65):\n",
    "    \"\"\"\n",
    "    Generate synthetic ARPU time series data with trends and seasonality.\n",
    "    \n",
    "    Args:\n",
    "        start_date: Start date for the time series\n",
    "        end_date: End date for the time series\n",
    "        base_arpu: Base ARPU value\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with date and ARPU columns\n",
    "    \"\"\"\n",
    "    # Create date range\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    \n",
    "    # Create trend component (gradual increase with some fluctuations)\n",
    "    days = len(dates)\n",
    "    trend = np.linspace(0, 0.15, days)  # 15% growth over period\n",
    "    \n",
    "    # Add cyclical components\n",
    "    yearly_cycle = 5 * np.sin(2 * np.pi * np.arange(days) / 365.25)\n",
    "    quarterly_cycle = 3 * np.sin(2 * np.pi * np.arange(days) / 91.31)\n",
    "    \n",
    "    # Weekly seasonality (higher ARPU on weekdays)\n",
    "    weekly_effect = np.zeros(days)\n",
    "    for i, date in enumerate(dates):\n",
    "        day_of_week = date.weekday()\n",
    "        if day_of_week < 5:  # Monday-Friday\n",
    "            weekly_effect[i] = 2  # Slightly higher on weekdays\n",
    "        else:\n",
    "            weekly_effect[i] = -1  # Lower on weekends\n",
    "    \n",
    "    # Monthly patterns (billing cycles)\n",
    "    monthly_effect = np.zeros(days)\n",
    "    for i, date in enumerate(dates):\n",
    "        if date.day <= 7:  # First week of month\n",
    "            monthly_effect[i] = 3  # Higher after billing\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, 2, days)\n",
    "    \n",
    "    # Combine components\n",
    "    arpu_values = base_arpu * (1 + trend) + yearly_cycle + quarterly_cycle + weekly_effect + monthly_effect + noise\n",
    "    \n",
    "    # Ensure positive values\n",
    "    arpu_values = np.maximum(arpu_values, 10)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'ds': dates,\n",
    "        'y': arpu_values\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the time series\n",
    "arpu_data = generate_arpu_time_series()\n",
    "print(f\"Generated {len(arpu_data)} days of ARPU data\")\n",
    "print(f\"Date range: {arpu_data['ds'].min()} to {arpu_data['ds'].max()}\")\n",
    "print(f\"ARPU range: ${arpu_data['y'].min():.2f} to ${arpu_data['y'].max():.2f}\")\n",
    "arpu_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a12069b",
   "metadata": {},
   "source": [
    "## 2. Visualize the Time Series Data\n",
    "\n",
    "Let's examine the generated ARPU data to understand its patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f849eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(arpu_data['ds'], arpu_data['y'], linewidth=1, alpha=0.7)\n",
    "plt.title('Synthetic ARPU Time Series', fontsize=16)\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('ARPU ($)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show basic statistics\n",
    "print(\"ARPU Statistics:\")\n",
    "print(arpu_data['y'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a3011",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Prophet\n",
    "\n",
    "Prophet requires the data to have specific column names: 'ds' for dates and 'y' for values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af558664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet requires columns to be named 'ds' and 'y'\n",
    "prophet_data = arpu_data.copy()\n",
    "print(\"Data prepared for Prophet modeling\")\n",
    "prophet_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331167ea",
   "metadata": {},
   "source": [
    "## 4. Train Prophet Model\n",
    "\n",
    "We'll split the data into training and testing sets, then train the Prophet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80/20 split)\n",
    "split_date = prophet_data['ds'].quantile(0.8)\n",
    "train_data = prophet_data[prophet_data['ds'] <= split_date]\n",
    "test_data = prophet_data[prophet_data['ds'] > split_date]\n",
    "\n",
    "print(f\"Training data: {len(train_data)} days ({train_data['ds'].min()} to {train_data['ds'].max()})\")\n",
    "print(f\"Test data: {len(test_data)} days ({test_data['ds'].min()} to {test_data['ds'].max()})\")\n",
    "\n",
    "# Initialize and configure Prophet model\n",
    "model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    daily_seasonality=False,\n",
    "    seasonality_mode='multiplicative',\n",
    "    changepoint_prior_scale=0.05,  # Flexibility of trend changes\n",
    "    seasonality_prior_scale=10.0,  # Flexibility of seasonality\n",
    "    interval_width=0.95  # 95% uncertainty intervals\n",
    ")\n",
    "\n",
    "# Add custom seasonalities\n",
    "model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "model.add_seasonality(name='quarterly', period=91.25, fourier_order=4)\n",
    "\n",
    "# Fit the model\n",
    "print(\"\\nTraining Prophet model...\")\n",
    "model.fit(train_data)\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e01ff38",
   "metadata": {},
   "source": [
    "## 5. Make Predictions\n",
    "\n",
    "Now we'll use the trained model to make predictions on the test set and future dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd31a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create future dataframe for predictions\n",
    "future = model.make_future_dataframe(periods=90)  # Predict next 90 days\n",
    "print(f\"Future dataframe created with {len(future)} rows\")\n",
    "\n",
    "# Make predictions\n",
    "forecast = model.predict(future)\n",
    "print(\"Predictions completed!\")\n",
    "\n",
    "# Display forecast results\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abbba9",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model Performance\n",
    "\n",
    "Let's evaluate how well our model performs on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff989ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge actual values with predictions for test period\n",
    "test_forecast = forecast[forecast['ds'].isin(test_data['ds'])]\n",
    "evaluation_df = test_data.merge(test_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds')\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(evaluation_df['y'], evaluation_df['yhat'])\n",
    "rmse = math.sqrt(mean_squared_error(evaluation_df['y'], evaluation_df['yhat']))\n",
    "mape = np.mean(np.abs((evaluation_df['y'] - evaluation_df['yhat']) / evaluation_df['y'])) * 100\n",
    "\n",
    "print(\"=== MODEL EVALUATION METRICS ===\")\n",
    "print(f\"Mean Absolute Error (MAE): ${mae:.2f}\")\n",
    "print(f\"Root Mean Square Error (RMSE): ${rmse:.2f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Check how many actual values fall within prediction intervals\n",
    "within_interval = ((evaluation_df['y'] >= evaluation_df['yhat_lower']) & \n",
    "                   (evaluation_df['y'] <= evaluation_df['yhat_upper'])).mean() * 100\n",
    "print(f\"Percentage within 95% confidence interval: {within_interval:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711055c",
   "metadata": {},
   "source": [
    "## 7. Visualize Results\n",
    "\n",
    "Let's visualize the forecast along with actual values and components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983637b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecast with actual values\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "# Plot actual values\n",
    "ax.plot(train_data['ds'], train_data['y'], 'k-', alpha=0.5, label='Historical (Training)')\n",
    "ax.plot(test_data['ds'], test_data['y'], 'k-', alpha=0.8, label='Actual (Test)')\n",
    "\n",
    "# Plot forecast\n",
    "ax.plot(forecast['ds'], forecast['yhat'], 'b-', label='Forecast')\n",
    "ax.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], \n",
    "                color='blue', alpha=0.2, label='95% Confidence Interval')\n",
    "\n",
    "# Add vertical line to separate train/test\n",
    "ax.axvline(x=split_date, color='red', linestyle='--', alpha=0.7, label='Train/Test Split')\n",
    "\n",
    "ax.set_title('ARPU Forecasting with Prophet', fontsize=16)\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('ARPU ($)', fontsize=12)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376cccef",
   "metadata": {},
   "source": [
    "## 8. Analyze Forecast Components\n",
    "\n",
    "Prophet decomposes the forecast into trend, seasonality, and holiday components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a54449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot components\n",
    "fig2 = model.plot_components(forecast)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e34ee",
   "metadata": {},
   "source": [
    "## 9. Business Insights\n",
    "\n",
    "Let's extract some business insights from our forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4cd7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trend component\n",
    "trend_data = forecast[['ds', 'trend']].copy()\n",
    "trend_data['year'] = trend_data['ds'].dt.year\n",
    "trend_data['month'] = trend_data['ds'].dt.month\n",
    "\n",
    "# Calculate yearly growth rate\n",
    "yearly_avg = trend_data.groupby('year')['trend'].mean()\n",
    "growth_rates = yearly_avg.pct_change() * 100\n",
    "\n",
    "print(\"=== ARPU TREND ANALYSIS ===\")\n",
    "print(\"Yearly Average ARPU:\")\n",
    "for year, avg_arpu in yearly_avg.items():\n",
    "    print(f\"  {year}: ${avg_arpu:.2f}\")\n",
    "\n",
    "print(\"\\nYear-over-Year Growth Rates:\")\n",
    "for year, growth in growth_rates.items():\n",
    "    if not np.isnan(growth):\n",
    "        print(f\"  {year}: {growth:.2f}%\")\n",
    "\n",
    "# Forecast next quarter revenue\n",
    "next_quarter = forecast[forecast['ds'] > test_data['ds'].max()].head(90)\n",
    "avg_forecast_arpu = next_quarter['yhat'].mean()\n",
    "print(f\"\\nForecasted Average ARPU (Next 90 days): ${avg_forecast_arpu:.2f}\")\n",
    "\n",
    "# Assuming 10,000 customers\n",
    "estimated_customers = 10000\n",
    "projected_quarterly_revenue = avg_forecast_arpu * estimated_customers * 90 / 30\n",
    "print(f\"Projected Quarterly Revenue (10k customers): ${projected_quarterly_revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104365cd",
   "metadata": {},
   "source": [
    "## 10. Model Improvements\n",
    "\n",
    "Let's explore some ways to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4053e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add external regressors (hypothetical factors that might affect ARPU)\n",
    "def add_regressors(df):\n",
    "    \"\"\"Add external regressors to the data.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Marketing spend (hypothetical)\n",
    "    df['marketing_spend'] = 5000 + 2000 * np.sin(2 * np.pi * np.arange(len(df)) / 365.25) + \\\n",
    "                           np.random.normal(0, 500, len(df))\n",
    "    \n",
    "    # Economic indicator (hypothetical)\n",
    "    df['economic_index'] = 100 + 5 * np.sin(2 * np.pi * np.arange(len(df)) / 91.25) + \\\n",
    "                          np.random.normal(0, 2, len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Add regressors to our data\n",
    "extended_data = add_regressors(prophet_data)\n",
    "\n",
    "# Split data\n",
    "train_extended = extended_data[extended_data['ds'] <= split_date]\n",
    "test_extended = extended_data[extended_data['ds'] > split_date]\n",
    "\n",
    "# Create enhanced model with regressors\n",
    "enhanced_model = Prophet(\n",
    "    yearly_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    seasonality_mode='multiplicative'\n",
    ")\n",
    "\n",
    "# Add regressors to model\n",
    "enhanced_model.add_regressor('marketing_spend')\n",
    "enhanced_model.add_regressor('economic_index')\n",
    "\n",
    "# Fit enhanced model\n",
    "print(\"Training enhanced model with external regressors...\")\n",
    "enhanced_model.fit(train_extended)\n",
    "print(\"Enhanced model training completed!\")\n",
    "    \n",
    "# Create future dataframe with regressors\n",
    "future_extended = enhanced_model.make_future_dataframe(periods=90)\n",
    "future_extended = add_regressors(future_extended)\n",
    "    \n",
    "# Make predictions with enhanced model\n",
    "enhanced_forecast = enhanced_model.predict(future_extended)\n",
    "    \n",
    "# Compare models\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "print(\"Base Model MAE:\", f\"${mae:.2f}\")\n",
    "    \n",
    "# Calculate MAE for enhanced model\n",
    "test_enhanced_forecast = enhanced_forecast[enhanced_forecast['ds'].isin(test_data['ds'])]\n",
    "enhanced_mae = mean_absolute_error(evaluation_df['y'], test_enhanced_forecast['yhat'])\n",
    "print(\"Enhanced Model MAE:\", f\"${enhanced_mae:.2f}\")\n",
    "    \n",
    "improvement = (mae - enhanced_mae) / mae * 100\n",
    "print(f\"Improvement: {improvement:.2f}%\")\n",
    "    \n",
    "print(\"\\nARPU forecasting with Prophet completed successfully!\")\n",
    "print(\"This model can help predict future revenue and identify seasonal patterns.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
