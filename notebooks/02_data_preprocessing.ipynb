{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1623d6d",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Engineering\n",
    "## Notebook 02: Data Cleaning and Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c9e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/raw/master_dataset.csv')\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae1c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RFM features\n",
    "df['recency_score'] = np.where(df['tenure_months'] <= 6, 5,\n",
    "                      np.where(df['tenure_months'] <= 12, 4,\n",
    "                      np.where(df['tenure_months'] <= 24, 3,\n",
    "                      np.where(df['tenure_months'] <= 36, 2, 1))))\n",
    "\n",
    "total_sessions = df['monthly_web_sessions'] + df['monthly_app_sessions']\n",
    "df['frequency_score'] = pd.qcut(total_sessions + df['support_tickets_12m'], \n",
    "                              q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "\n",
    "df['monetary_score'] = pd.qcut(df['arpu'], q=5, labels=[1, 2, 3, 4, 5]).astype(int)\n",
    "df['rfm_score'] = df['recency_score'] + df['frequency_score'] + df['monetary_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage pattern features\n",
    "df['data_usage_ratio'] = df['monthly_data_gb'] / (df['data_allowance_gb'] + 1e-6)\n",
    "df['usage_efficiency'] = (df['data_usage_ratio'] + df['monthly_minutes']/(df['minutes_allowance'] + 1e-6)) / 2\n",
    "df['data_overage'] = (df['monthly_data_gb'] > df['data_allowance_gb']).astype(int)\n",
    "\n",
    "# Risk features\n",
    "risk_mapping = {'High': 3, 'Medium': 2, 'Low': 1}\n",
    "df['satisfaction_risk'] = np.where(df['satisfaction_score'] <= 5, 'High',\n",
    "                          np.where(df['satisfaction_score'] <= 7, 'Medium', 'Low'))\n",
    "df['composite_risk_score'] = df['satisfaction_risk'].map(risk_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e63175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer segmentation\n",
    "def assign_value_segment(row):\n",
    "    if row['arpu'] >= 80 and row['satisfaction_score'] >= 8:\n",
    "        return 'Champions'\n",
    "    elif row['arpu'] >= 60 and row['satisfaction_score'] >= 7:\n",
    "        return 'Potential Loyalists'\n",
    "    elif row['arpu'] >= 40 and row['satisfaction_score'] >= 6:\n",
    "        return 'New Customers'\n",
    "    else:\n",
    "        return 'Need Attention'\n",
    "\n",
    "df['customer_segment'] = df.apply(assign_value_segment, axis=1)\n",
    "print(df['customer_segment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e37c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for modeling\n",
    "df_model = df.copy()\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = ['plan_type', 'gender', 'city', 'customer_segment', 'satisfaction_risk']\n",
    "for col in categorical_cols:\n",
    "    if col in df_model.columns:\n",
    "        dummies = pd.get_dummies(df_model[col], prefix=col, drop_first=True)\n",
    "        df_model = pd.concat([df_model, dummies], axis=1)\n",
    "        df_model.drop(columns=[col], inplace=True)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "cols_to_remove = ['customer_id', 'join_date', 'churn_date', 'churn_probability']\n",
    "df_model = df_model.drop(columns=cols_to_remove, errors='ignore')\n",
    "\n",
    "print(f\"Final dataset shape: {df_model.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0d33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "df_model.to_csv('../data/processed/processed_dataset.csv', index=False)\n",
    "print(\"Processed dataset saved!\")\n",
    "\n",
    "# Feature importance analysis\n",
    "numeric_features = df_model.select_dtypes(include=[np.number]).columns.tolist()\n",
    "churn_correlations = df_model[numeric_features].corrwith(df_model['churned']).abs().sort_values(ascending=False)\n",
    "print(\"\\nTop 10 features correlated with churn:\")\n",
    "print(churn_correlations.head(10))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
